# Data
The goal of this project being to investigate the correlation between sports betting rates and education/income trends across U.S. states, we collected and compiled data from multiple sources. The first dataset, titled Online Sports Betting Dataset, was the most straightforward. This data was retrieved via download directly from rg.org/statistics/us. In contrast, collecting income and education data from the U.S. Census (covering the years 2018â€“2023) proved more complex. The range from 2018-2023 was selected because it represents the overlap of available years across all relevant datasets. However, due to the structure of the Census API, each year and state combination required a unique API. Additionally, the topic parameter (either income or education) had to be specified separately. This meant that retrieving data for all 50 states across six years, for two topics, would have required 384 manual downloads and subsequent joins. To avoid this, we built a web scraper using Docker, Supabase, PostgreSQL, and Beekeeper Studio. The scraper looped through the `year` and `GeoID` values in the API URL to pull each required combination in one run. However, we opted to run the scraper twice, once for income and once for education, manually replacing the topic ID in the `scraper.py` file between runs, rather than building the scraper to run both topics. The logic behind this decision was that it was simpler to change one number in the `scraper.py` file and run it a second time, than create a scraper that switched which table it was dumping into halfway through, since storing education and income in two individual tables was better for the planned analysis. 

Once scraped, we employed SQL to clean and normalize the raw JSON responses into tabular CSV format. Rather than storing all columns from the original census datasets, we selected only the variables relevant to our analysis. This process resulted in three final tables: the sports betting dataset, the cleaned income dataset, and the cleaned education dataset, all of which were stored on local systems for the remainder of the project. For each dataset, we performed several operations to ensure consistency across columns and formats. We first conducted basic data cleaning and wrangling where the column values and names were altered to be consistent among all the data. The next step was finding a common variable among our three datasets. `Geoid` and `year` became our primary identifiers across our sports betting, cleaned income, and cleaned education datasets. This also allowed for simple screening for duplicates among the tables that may have the same geoid and year, and we were able to filter those out quickly. We created a location table that showed the corresponding state name to each geoID, which worked as a connection between all tables. After that we normalized the data structure in a way we believed was efficient for our planned analysis, see ERD below.

<figure id="fig-erd">
  <img src="figures/figure1a.png" alt="ERD diagram" width="800">
  <figcaption style="font-size: 8px; color: #555;">
    Figure 1: This figure displays an ERD normalized to third normal form (3NF), highlighting primary keys and table relationships.
  </figcaption>
</figure>


As seen above, to support analysis of the relationship between sports betting activity and socioeconomic trends across U.S. states, the data was structured into a schema that separates income, education, and betting metrics into connected tables to facilitate flexible joins. `Geoid` and `year` serve as foreign keys linking all domain-specific tables (income, education, and sports betting) to the central location table that maps each geoid to a state-level place_name. Income data is organized into two fact tables. The income_distribution table captures the percentage of households within each income bracket and household type, while the income_summary table provides metrics such as total households, median income, and mean income by household type. These reference the income_brackets and household_type dimension tables for consistency. Education data is stored in the edu_long table, which reports the number of individuals by education level and age group. It joins the age_group_map table to normalize age categories. Sports betting data is stored in clean_sports, which contains metrics such as handle, revenue, hold, and taxes. This table integrates with the rest of the schema via shared identifiers. This structure allows for efficient querying as we explore the research question.
